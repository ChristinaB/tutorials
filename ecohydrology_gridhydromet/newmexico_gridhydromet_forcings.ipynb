{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://landlab.github.io/assets/Landlab-logo.png\"\n",
    "style=\"float:left;width:150px;padding:0px\">  \n",
    "\n",
    "# Lowering the barriers to computational modeling of Earthâ€™s surface: coupling Jupyter Notebooks with Landlab, HydroShare, and CyberGIS for research and education <br /> \n",
    "<br /> \n",
    "### Use Case 2: Gridded Hydrometeorology forcing a Cellular Automaton Vegetation-Ecohydrologic Model\n",
    "* Load data from a Landlab model published on HydroShare. <br />\n",
    "* Define a geographic subset (New Mexico) within the North America.\n",
    "* Calculate mean climatology for a range of elevation bands.\n",
    "* Run the Landlab ecohydrology model for a watershed given various climate scenarios.<br />\n",
    "* Explore sensitivity to climate by comparing the watershed model results.\n",
    "* Save results to a new HydroShare resource.  <br />\n",
    "\n",
    "## Sai- we need a citation here and to update the list below.  <br />\n",
    "\n",
    "#### This research is actively being developed by the Watershed Dynamics Research Group in the Civil and Environmental Engineering Department at the University of Washington for the Thunder Creek basin in the Skagit Watershed, WA, USA in collaboration with the HydroShare team, CUAHSI and NCSA partners.\n",
    " <br /> <img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:left;width:120px;padding:10px\">   \n",
    "<img src=\"http://www.ncsa.illinois.edu/assets/img/logos_ncsa.png\"\n",
    " style=\"float:right;width:120px;padding:10px\"> \n",
    "<img src=\"https://www.cuahsi.org/assets/images/logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<small> For instructions on how to run an interactive iPython notebook, click here: <a href=\"https://github.com/landlab/tutorials/blob/master/README.md\">https://github.com/landlab/tutorials/blob/master/README.md</a></small><br>\n",
    "<small>For the unexpanded version to download and run, click here: <a href=\"http://nbviewer.jupyter.org/github/landlab/tutorials/blob/master/ecohydrology/cellular_automaton_vegetation_DEM/cellular_automaton_vegetation_DEM_unexpanded.ipynb\">http://nbviewer.jupyter.org/github/landlab/tutorials/blob/master/ecohydrology/cellular_automaton_vegetation_DEM/cellular_automaton_vegetation_DEM_unexpanded.ipynb</a></small><br>\n",
    "<small>For more Landlab tutorials, click here: <a href=\"https://github.com/landlab/landlab/wiki/Tutorials\">https://github.com/landlab/landlab/wiki/Tutorials</a></small>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates implementation of the Cellular Automaton Tree-GRass-Shrub Simulator (CATGRaSS) [Zhou et al., 2013] on a flat domain. This model is built using components from the Landlab component library. CATGRaSS is spatially explicit model of plant coexistence. It simulates local ecohydrologic dynamics (soil moisture, transpiration, biomass) and spatial evolution of tree, grass, and shrub Plant Functional Types (PFT) driven by rainfall and solar radiation. \n",
    "\n",
    "Each cell in the model grid can hold a single PFT or remain empty. Tree and shrub plants disperse seeds to their neighbors. Grass seeds are assumed to be available at each cell. Establishment of plants in empty cells is determined probabilistically based on water stress of each PFT. Plants with lower water stress have higher probability of establishment. Plant mortality is simulated probabilistically as a result of aging and drought stress. Fires and grazing will be added to this model soon.  \n",
    "\n",
    "This model (driver) contains:\n",
    "  - A local vegetation dynamics model that simulates storm and inter-storm water balance and ecohydrologic fluxes (ET, runoff), and plant biomass dynamics by coupling the following components:\n",
    "        - PrecipitationDistribution\n",
    "        - Radiation\n",
    "        - PotentialEvapotranspiration\n",
    "        - SoilMoisture\n",
    "        - Vegetation\n",
    "\n",
    "  - A spatially explicit probabilistic cellular automaton component that simulates plant competition by tracking establishment and mortality of plants based on soil moisture stress:\n",
    "        - VegCA\n",
    "    \n",
    "To run this Jupyter notebook, please make sure that the following files are in the same folder:\n",
    "        - cellular_automaton_vegetation_flat_domain.ipynb (this notebook)\n",
    "        - Inputs_Vegetation_CA.txt (Input parameters for the model)\n",
    "        - Ecohyd_functions_flat.py (Utility functions)\n",
    "\n",
    "[Ref: Zhou, X, E. Istanbulluoglu, and E.R. Vivoni. \"Modeling the ecohydrological role of aspect-controlled radiation on tree-grass-shrub coexistence in a semiarid climate.\" Water Resources Research 49.5 (2013): 2872-2895]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to work with a landscape in central New Mexico, USA, where aspect controls the organization of PFTs. The climate in this area is semi-arid with Mean Annual Precipitation (MAP) of 254 mm [Zhou et. al 2013]. \n",
    "We will do the following: \n",
    "- Import a landscape \n",
    "- Initialize the landscape with random distribution of PFTs\n",
    "- Run the coupled Ecohydrology and cellular automata plant competition model for 50 years\n",
    "- Visualize and examine outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Notebook Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libraries.\n",
    "The hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading. and creation. Additional libraries support the functions of Landlab.\n",
    "### 1a.  Import libraries installed on CUAHSI JupyterHub server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python libraries available on CUAHSI JupyterHub \n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#HydroShare Utilities\n",
    "from utilities import hydroshare\n",
    "hs=hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables for interacting with HydroShare from this notebook\n",
    "<br />\n",
    "The home directory on the JupyterHub server is printed. You can navigate to see the data using a terminal or folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b.  Import python scripts from a Github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please see the [Observatory]( https://github.com/ChristinaB/Observatory/blob/master/README.md) repository on Github with a Readme instructions on how to use Git and the JupyterHub server terminal to push/pull changes.   After completing the steps to get the observatory_gridded_hydromet.py script into your HydroShare Utilities folder, execute the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ogh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir = ogh.mapContentFolder(str(os.environ[\"HS_RES_ID\"]))\n",
    "print('Data will be loaded from and save to:'+homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and generate lists of gridded climate points for a watershed\n",
    "Retrieve a list of grid points and configuration file from a HydroShare resource\n",
    "This example uses a ascii text that is stored in HydroShare at the following url: https://www.hydroshare.org/resource/d90289409f904017831d308642c1eb30/ . The data for our processing routines can be retrieved using the getResourceFromHydroShare function by passing in the global identifier from the url above.  In the next cell, we download this resource from HydroShare, and identify that the table in this resource is the 'mappingfile' variable identifying the Lat/Long points to be used for downloading hydrometeorology data.  The file must include columns with station numbers (this can be aribitrary), latitude, longitude, and elevation. The header of these columns must be FID, LAT, LONG_, and ELEV or RASTERVALU, respectively. The station numbers will be used for the remainder of the code to uniquely reference data from each climate station, as well as to identify minimum, maximum, and average elevation of all of the climate stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download areas of interest from HydroShare Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This resource type is Composite Resource containing a Geographic Feature (ESRI Shapefile). \n",
    "hs.getResourceFromHydroShare('5b401852758e4d49a87a788c1008b027')\n",
    "download_extent_shapefile = hs.content['New_Mexico.shp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TreatGeoSelf to a mapping tool that uses your shapefile\n",
    "# Reuse this exising point shapefile of available 1/16 degree grid centroid locations \n",
    "# shared on HydroShare as a public resource\n",
    "hs.getResourceFromHydroShare('ef2d82bf960144b4bfb1bae6242bcc7f')\n",
    "NAmer = hs.content['NAmer_dem_list.shp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Observatory metadata file \n",
    "This file contains the variables, data types and metadata related to Livneh et al., 2013; 2015 and Salathe et al., 2014 gridded hydrometeorology products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming this is pulled from Github, how can we import this from Utilities.\n",
    "#Otherwise it needs to be in each HydroShare resource - which if fine too. \n",
    "# initialize ogh_meta data file\n",
    "meta_file = dict(ogh.ogh_meta())\n",
    "sorted(meta_file.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreatGeoSelf() to a easily generated list of lat/long points in your area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#New Mexico Extent is approximately 7900 gridded cells\n",
    "mappingfile = ogh.treatgeoself(shapefile=download_extent_shapefile, \n",
    "                               NAmer=NAmer, \n",
    "                               buffer_distance=0,\n",
    "                               mappingfile=os.path.join(homedir,'new_mexico_gridmet.csv'))\n",
    "print(mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogh.griddedCellGradient(mappingfile=mappingfile, \n",
    "                        shapefile=download_extent_shapefile,\n",
    "                        outfilepath=os.path.join(homedir, 'NM_elev_gradient.png'),\n",
    "                        plottitle='New Mexico watershed\\nGridded cell elevation gradient',\n",
    "                        colorbar_label='Average elevation (meters)',\n",
    "                        spatial_resolution=1/16, margin=0.25, epsg=3857, column='ELEV',\n",
    "                        basemap_image='Elevation/World_Hillshade', cmap='terrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Download gridded climate data \n",
    " ### Get Daily Meteorologic Data from  Livneh et al. 2015 (1950-2013; North America extent)\n",
    "\n",
    "Please cite 2015 data with: <br/>\n",
    "Livneh B., T.J. Bohn, D.S. Pierce, F. Munoz-Ariola, B. Nijssen, R. Vose, D. Cayan, and L.D. Brekke, 2015: A spatially comprehensive, hydrometeorological data set for Mexico, the U.S., and southern Canada 1950-2013, Nature Scientific Data, 5:150042, doi:10.1038/sdata.2015.42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # uncomment and run if the files have already been downloaded\n",
    "# ogh.remapCatalog(homedir=homedir, \n",
    "#                  mappingfile=mappingfile, \n",
    "#                  subdir='livneh2015/Daily_MET_1950_2013/raw', \n",
    "#                  catalog_label='dailymet_livneh2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# From the reference mapping file, read-in, download, and unzip the data files for the longitude and latitude points\n",
    "ogh.getDailyMET_livneh2015(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = ogh.mappingfileSummary(listofmappingfiles = [mappingfile], \n",
    "                            listofwatershednames = ['New Mexico'],\n",
    "                            meta_file=meta_file)\n",
    "\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Create gridded climate data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dictionary of the original time series from Livneh and WRF, the monthly average statistics for each grid cell will be used to calculate differences between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elev=0\n",
    "max_elev=1500\n",
    "\n",
    "ltm_low = ogh.gridclim_dict(mappingfile=mappingfile,\n",
    "                            dataset='dailymet_livneh2015',\n",
    "                            metadata=meta_file,\n",
    "                            min_elev=min_elev,\n",
    "                            max_elev=max_elev)\n",
    "\n",
    "ogh.saveDictOfDf(dictionaryObject=ltm_low, outfilepath=os.path.join(homedir,'NewMexico_lowElevation.json'))\n",
    "\n",
    "sorted(ltm_low.keys())\n",
    "del ltm_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elev=1500\n",
    "max_elev=2500\n",
    "\n",
    "ltm_mid = ogh.gridclim_dict(mappingfile=mappingfile,\n",
    "                            dataset='dailymet_livneh2015',\n",
    "                            metadata=meta_file,\n",
    "                            min_elev=min_elev,\n",
    "                            max_elev=max_elev)\n",
    "\n",
    "ogh.saveDictOfDf(dictionaryObject=ltm_mid, outfilepath=os.path.join(homedir,'NewMexico_midElevation.json'))\n",
    "\n",
    "sorted(ltm_mid.keys())\n",
    "del ltm_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elev=2500\n",
    "max_elev=3500\n",
    "\n",
    "ltm_high = ogh.gridclim_dict(mappingfile=mappingfile,\n",
    "                             dataset='dailymet_livneh2015',\n",
    "                             metadata=meta_file,\n",
    "                             min_elev=min_elev,\n",
    "                             max_elev=max_elev)\n",
    "\n",
    "ogh.saveDictOfDf(dictionaryObject=ltm_high, outfilepath=os.path.join(homedir,'NewMexico_highElevation.json'))\n",
    "\n",
    "sorted(ltm_high.keys())\n",
    "del ltm_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elev=0\n",
    "max_elev=3500\n",
    "\n",
    "ltm_all = ogh.gridclim_dict(mappingfile=mappingfile,\n",
    "                            dataset='dailymet_livneh2015',\n",
    "                            metadata=meta_file,\n",
    "                            min_elev=min_elev,\n",
    "                            max_elev=max_elev)\n",
    "\n",
    "ogh.saveDictOfDf(dictionaryObject=ltm_all, outfilepath=os.path.join(homedir,'NewMexico_allElevation.json'))\n",
    "\n",
    "sorted(ltm_all.keys())\n",
    "del ltm_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a Dictionary and convert meteorology data from pandas dataframe into numpy arrays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
